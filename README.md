# OpenAI-Compatible Gemini Chatbot

A chatbot built to be compatible with OpenAIâ€™s API while leveraging Geminiâ€™s capabilities.

## ğŸš€ Live Deployment

You can access the live deployment here:  
[**Gemini Chatbot on Vercel**](https://gemini-chiefkarim-chiefkarims-projects.vercel.app/docs)

---

## ğŸ“– Table of Contents

- [Introduction](#-introduction)
- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Configuration](#-configuration)
- [Project Structure](#-project-structure)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸŒŸ Introduction

This chatbot integrates OpenAI-compatible API endpoints to support interactions with Geminiâ€™s models. It is built using Python and deployed on **Vercel**.

## âœ¨ Features

- OpenAI API-compatible interface.
- Supports chatbot conversations.
- Easily deployable via Vercel.
- Structured routes for handling API requests.
- Configurable via environment variables.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone git@github.com:chiefkarim/gemini.git
cd gemini
```

### 2ï¸âƒ£ Set Up a Virtual Environment Using `uv`

```bash
uv venv  # Create a virtual environment
```

### 3ï¸âƒ£ Activate the Virtual Environment

```bash
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
```

### 4ï¸âƒ£ Install Dependencies Using `uv`

```bash
uv install
```

### 5ï¸âƒ£ Set Up Environment Variables

Create a `.env` file and configure it based on your API keys and settings.

---

## ğŸš€ Usage

### Running Locally

```bash
uvicorn routes.app:app --reload
```

This will start the API server locally.

### Running in Production

Use the following command to run the chatbot in a production-ready setup:

```bash
uvicorn routes.app:app --host 0.0.0.0 --port 8000 --workers 4
```

This will:

- Bind the app to **all network interfaces (`0.0.0.0`)** so it's accessible externally.
- Run on **port 8000** (change as needed).
- Use **4 worker processes** for handling multiple requests efficiently.

## For **Vercel deployment**, the server will automatically start using the configurations defined in `vercel.json`

---

## ğŸ”§ Configuration

Environment variables are stored in `.env`. A sample configuration is provided in `.env.example`.

To set up your environment, copy `.env.example` and rename it to `.env`:

```bash
cp .env.example .env
```

---

## ğŸ—‚ï¸ Project Structure

```

gemini/
â”‚â”€â”€ models/ # Data models and schemas
â”‚â”€â”€ routes/ # API route handlers
â”‚â”€â”€ services/ # Core logic for chatbot interactions
â”‚â”€â”€ scripts/ # Utility scripts
â”‚â”€â”€ .env # Environment variables (ignored in Git)
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ pyproject.toml # Project configuration
â”‚â”€â”€ vercel.json # Deployment settings
â”‚â”€â”€ README.md # Documentation

```

---

## ğŸ¤ Contributing

Contributions are welcome! Please fork the repo and submit a PR.

---

## ğŸ“œ License

[MIT License](LICENSE) â€“ Feel free to modify and use this project.

```

---

Now it correctly uses `uv install` instead of `uv pip install`. Let me know if you need any more refinements! ğŸš€ğŸ”¥

```

```

```
